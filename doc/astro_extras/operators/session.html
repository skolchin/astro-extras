<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>astro_extras.operators.session API documentation</title>
<meta name="description" content="ETL session management routines" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>astro_extras.operators.session</code></h1>
</header>
<section id="section-intro">
<p>ETL session management routines</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Astro SDK Extras project
# (c) kol, 2023

&#34;&#34;&#34; ETL session management routines &#34;&#34;&#34;

import re
from datetime import datetime, timedelta
from dateutil.parser import isoparse

from airflow.models import DAG, BaseOperator
from airflow.models.xcom_arg import XComArg
from airflow.models.dag import DagContext
from airflow.operators.python import get_current_context
from airflow.utils.context import Context
from airflow.utils.state import TaskInstanceState
from airflow.utils.trigger_rule import TriggerRule
from airflow.exceptions import AirflowException, AirflowFailException
from airflow.settings import TIMEZONE

from attr import define, field
from astro import sql as aql
from astro.sql.operators.raw_sql import RawSQLOperator
from typing import Optional, Union, Any, Tuple, cast

from ..utils.datetime_local import datetime_to_tz

@define(slots=False)
class ETLSession:
    &#34;&#34;&#34; Session data object. Holds all ETL session attributes, can be pushed to XCom.
    Implements context manager protocol (see examples).

    Args:
        source_conn_id:   Source connection ID
        destination_conn_id:   Destination connection ID
        session_conn_id:   ID of connection, where `public.sessions` table is located.
            If not set, then `destination_conn_id` is used
        session_id:   Actual session ID (automatically generated, do not set it)
        period_start: Date and time of session period start as ISO-format string.
            See `open_session` for details.
        period_end: Date and time of session period end as ISO-format string.
            See `open_session` for details.
        dag: DAG, where the session was created. Used only to pass DAG&#39;s reference throught.

    Examples:
        Using `ETLSession` as context manager:
        &gt;&gt;&gt; with DAG(...) as dag, ETLSession(&#39;source&#39;, &#39;target&#39;) as session:
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)

        Explicit call to `open_session`:        
        &gt;&gt;&gt; with DAG(...) as dag:
        &gt;&gt;&gt;     session = open_session(&#39;source&#39;, &#39;target&#39;)
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)
        &gt;&gt;&gt;     close_session(session)
    &#34;&#34;&#34;
    source_conn_id: str = field(default=None)
    destination_conn_id: str = field(default=None)
    session_conn_id: str = field(default=None)
    session_id: int = field(default=0)
    period_start: str = field(default=None)
    period_end: str = field(default=None)
    dag: DAG = field(default=None)

    def __attrs_post_init__(self) -&gt; None:
        if not self.session_conn_id:
            self.session_conn_id = self.destination_conn_id

    def __getstate__(self):
        return self.__dict__

    def serialize(self):
        return {
            &#39;source_conn_id&#39;: self.source_conn_id,
            &#39;destination_conn_id&#39;: self.destination_conn_id,
            &#39;session_conn_id&#39;: self.session_conn_id,
            &#39;session_id&#39;: self.session_id,
            &#39;period_start&#39;: self.period_start,
            &#39;period_end&#39;: self.period_end,
        }

    @staticmethod
    def deserialize(data, version: int):
        return ETLSession(
            source_conn_id=data[&#39;source_conn_id&#39;],
            destination_conn_id=data[&#39;destination_conn_id&#39;],
            session_conn_id=data[&#39;session_conn_id&#39;],
            session_id=data[&#39;session_id&#39;],
            period_start=data[&#39;period_start&#39;],
            period_end=data[&#39;period_end&#39;],
        )

    def __enter__(self):
        self._actual_sesssion = open_session(
            source_conn_id=self.source_conn_id,
            destination_conn_id=self.destination_conn_id,
            session_conn_id=self.session_conn_id,
            dag=self.dag)
        return self._actual_sesssion

    def __exit__(self, type, value, traceback):
        dag = cast(DAG, DagContext.get_current_dag())
        if len(dag.tasks) &gt; 1:
            t1, t2 = dag.tasks[0], dag.tasks[1]
            if t1.task_id == &#39;open-session&#39; and &#39;open-session&#39; not in t2.upstream_task_ids:
                t2.set_upstream(t1)
        close_session(self._actual_sesssion).set_downstream(aql.cleanup())

class OpenSessionOperator(BaseOperator):
    &#34;&#34;&#34; Session opening operator. Normally is used within `open_session` function &#34;&#34;&#34;

    def __init__(self,
                 *,
                 source_conn_id: Optional[str] = &#39;default&#39;,
                 destination_conn_id: Optional[str] = &#39;default&#39;,
                 session_conn_id: Optional[str] = None,
                 **kwargs):

        task_id = kwargs.pop(&#39;task_id&#39;, &#39;open-session&#39;)
        super().__init__(task_id=task_id, **kwargs)

        self.source_conn_id = source_conn_id
        self.destination_conn_id = destination_conn_id
        self.session_conn_id = session_conn_id if session_conn_id else destination_conn_id
        self.session: ETLSession = None

    def _new_session(self, period_start: str, period_end: str, context: Context) -&gt; int:
        # TBD: use of database-neutral statement
        sql = f&#34;&#34;&#34;insert into public.sessions(source, target, period, started, status, run_id) 
            values(&#39;{self.source_conn_id}&#39;,&#39;{self.destination_conn_id}&#39;,&#39;{{ {period_start}, {period_end} }}&#39;, 
            &#39;{datetime.now()}&#39;,&#39;running&#39;,&#39;{context[&#39;run_id&#39;]}&#39;) returning session_id&#34;&#34;&#34;

        op = RawSQLOperator(
            task_id=self.task_id,
            python_callable=lambda : sql,
            conn_id=self.session_conn_id,
            handler=lambda result: result.fetchone(),
            response_size=1)
        
        return op.execute(context)[0]

    def execute(self, context: Context):
        period_start, period_end = get_session_period(context)
        session_id = self._new_session(period_start, period_end, context)
        self.log.info(f&#39;New session {session_id} for period [{period_start},{period_end}] started&#39;)

        session = ETLSession(
            source_conn_id=self.source_conn_id,
            destination_conn_id=self.destination_conn_id, 
            session_id=session_id, 
            session_conn_id=self.session_conn_id,
            period_start=period_start,
            period_end=period_end)
        
        context[&#39;ti&#39;].xcom_push(key=&#39;session&#39;, value=session)
        return session

class CloseSessionOperator(BaseOperator):
    &#34;&#34;&#34; Session closing operator. Normally is used within `close_session` function &#34;&#34;&#34;

    def __init__(self,
                 *,
                 session: Union[ETLSession, XComArg, None] = None,
                 **kwargs):

        task_id = kwargs.pop(&#39;task_id&#39;, &#39;close-session&#39;)
        trigger_rule = kwargs.pop(&#39;trigger_rule&#39;, TriggerRule.ALL_DONE)
        super().__init__(task_id=task_id, trigger_rule=trigger_rule, **kwargs)
        self.session = session

    def execute(self, context: Context):
        self.session = ensure_session(self.session)

        dag_run = context[&#39;dag_run&#39;]
        failed_tasks = [ti for ti in dag_run.get_task_instances(state=TaskInstanceState.FAILED)]
        status = &#39;error&#39; if failed_tasks else &#39;success&#39;

        # TBD: use of database-neutral statement
        sql = f&#34;update public.sessions set finished=current_timestamp, status=&#39;{status}&#39; &#34; \
                   f&#34;where session_id={self.session.session_id}&#34;
        op = RawSQLOperator(
            task_id=self.task_id,
            python_callable=lambda : sql,
            conn_id=self.session.session_conn_id,
            response_size=1)
        op.execute(context)
        self.log.info(f&#39;Session {self.session.session_id} closed with status {status}&#39;)

        if status == &#39;error&#39;:
            raise AirflowException(&#39;Setting drives to idle&#39;)

def open_session(
        source_conn_id: str, 
        destination_conn_id: str, 
        session_conn_id: Optional[str] = None, 
        dag: Optional[DAG] = None,
        **kwargs) -&gt; XComArg:
    &#34;&#34;&#34; Opens a new ETL session.

    ETL session is a logical group of data transfers united by single identifier (`session_id`).
    Sessions store information about data transfer source, target, data loading period
    and completion state thus providing all necessary information about the data flow.

    Call to the `open_session` should be the 1st call in a data transfer DAG. It will
    create a new session by adding a record to `sessions` table and save a `ETLSession` instance 
    to XCom under &#34;session&#34; key. When using `ETLSession` class as a context manager,
    the call is performed implicitly.

    The session object could be retrieved from XCom and used within the queries.
        
    Note that ETL session object has `period_start` and `period_end` fields, which
    are calculated either automatically or could be specified manually by adding
    `{&#34;period&#34;: &#34;[&lt;period_start&gt;, &lt;period_end&gt;]&#34;}` parameter when DAG is started. 
    These fields can be used in data extraction queries to limit dataset like this:

        select * from data_table 
        where some_date 
            between &#39;{{ ti.xcom_pull(key=&#34;session&#34;).period_start }}&#39;::timestamp
            and &#39;{{ ti.xcom_pull(key=&#34;session&#34;).period_end }}&#39;::timestamp

    Technically, sessions are stored in a `public.sessions` table. Table DDL (for Postgres):

        create table public.sessions(
            session_id serial not null primary key,
            source text not null,
            target text not null,
            period timestamptz[2] not null,
            run_id text,
            started timestamptz not null,
            finished timestamptz,
            status varchar(10) not null 
                check (status in (&#39;running&#39;, &#39;success&#39;, &#39;error&#39;))
        );

    Every table where the data is saved should have an extra `session_id` field 
    referencing the `sessions` table. For example:

        create table public.test_table(
            session_id int not null references public.sessions(session_id),
            id int not null,
            name text not null
        );
    
    This allows to easily identify when particular record was loaded or 
    clean up after unsuccessfull attempts.

    Args:
        source_conn_id:   Airflow connection where source data resides
        destination_conn_id:   Airflow connection to transfer data to
        session_conn_id:   ID of connection, where `sessions` table is located.
            If not set, then `destination_conn_id` is used.

    Returns:
        An `XComArg` placeholder object indicating the session was created 
        - due to Airflow&#39;s architecture actual session object could not be accessed 
        at this point, but it will automatically be converted to real one
        upon passing in to the TaskFlow&#39;s task function (see examples).

    Examples:
        Create a DAG which opens a session, outputs info to log and closes it:

        &gt;&gt;&gt; with DAG(...) as dag, ETLSession(&#39;source&#39;, &#39;target&#39;) as session:
        &gt;&gt;&gt;     @dag.task
        &gt;&gt;&gt;     def print_session(session: Session):
        &gt;&gt;&gt;         print(session)
        &gt;&gt;&gt;     print_session(session)

        Create a DAG with `open-session -&gt; transfer-test_table -&gt; close_session`
        task sequence:

        &gt;&gt;&gt; with DAG(...) as dag:
        &gt;&gt;&gt;     session = open_session(&#39;source&#39;, &#39;target&#39;)
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)
        &gt;&gt;&gt;     close_session(session)

        Connections named `source` and `target` must be defined pointing to corresponding
        databases. Table `public.sessions` must exists in the target database.

        Table `test_table` must have the same structure in both databases, except
        that `session_id` field must be added to the target table as 1st column.

        See `astro_extras.operators.table.transfer_table` function for details on transfer operation.
    &#34;&#34;&#34;
    
    assert (dag := dag or DagContext.get_current_dag())
    return XComArg(OpenSessionOperator(
        dag=dag,
        source_conn_id=source_conn_id,
        destination_conn_id=destination_conn_id,
        session_conn_id=session_conn_id,
        **kwargs))

def close_session(
        session: Union[ETLSession, XComArg], 
        upstream_task: Optional[Any] = None,
        dag: Optional[DAG] = None,
        **kwargs) -&gt; XComArg:
    &#34;&#34;&#34; Closes the ETL session.

    Updates `public.sessions` table for currently running session
    saving completion time and state. If all tasks in a DAG run were successfull,
    session&#39;s state will be set to `success`, otherwise - to `error`. Note that 
    session closing task will also fail in later case in order to be
    automatically included into further retrying attempts.
    
    This function should be the last call in a DAG, and it will automatically try to link up 
    to the end of the task chain.
    
    If a `ETLSession` class is used as a context manager, `close_session` will be called
    implicitly.

    Args:
        session:    An object returned by `open_session`
        upstream_task:  A DAGs task which `close_session` task
            would be linked to. If not set, a last DAG&#39;s task will be used.

    Returns:
        An `XComArg` object indicating the session was closed

    Examples:
        See `open_session` for examples
    &#34;&#34;&#34;
    
    assert (dag := dag or DagContext.get_current_dag())
    if upstream_task is None:
        if not len(dag.tasks):
            raise ValueError(&#39;close_session must not be the first DAG operator&#39;)
        upstream_task = dag.tasks[-1]

    op = CloseSessionOperator(dag=dag, session=session, **kwargs)
    upstream_task.set_downstream(op)
    return XComArg(op)

def get_current_session(context: Optional[Context] = None) -&gt; ETLSession:
    &#34;&#34;&#34; Retrieves current session from XCom.
    
    Args:
        context:    DAG execution context (optional)

    Returns:
        Current ETL session as `ETLSession` class instance
    &#34;&#34;&#34;
    context = context or get_current_context()
    return context[&#39;ti&#39;].xcom_pull(key=&#39;session&#39;)

def ensure_session(session: Optional[Union[ETLSession, XComArg]], 
                   context: Optional[Context] = None) -&gt; ETLSession:
    &#34;&#34;&#34; Returns current session. If a placeholder object returned by `open_session` is passed in,
    retrieves actual session from XCom. 
    
    Args:
        session: Either the `ETLSession` instance or a placeholder returned by `open_session` call
        context:    DAG execution context (optional)

    Returns:
        Current ETL session as `ETLSession` class instance
    &#34;&#34;&#34;
    if session is None:
        return None
    if isinstance(session, ETLSession):
        return session
    if isinstance(session, XComArg):
        return get_current_session(context)
    raise TypeError(f&#39;Either ETLSession or XComArg expected, {session.__class__.__name__} found&#39;)

_TS_REGX = r&#39;\d{4}-([0]\d|1[0-2])-([0-2]\d|3[01])(T\d{2}:\d{2}:\d{2})?&#39;
_FULL_REGX = r&#39;\[\d{4}-([0]\d|1[0-2])-([0-2]\d|3[01])(T\d{2}:\d{2}:\d{2})?,\s*\d{4}-([0]\d|1[0-2])-([0-2]\d|3[01])(T\d{2}:\d{2}:\d{2})?]&#39;

def get_session_period(context: Optional[Context] = None) -&gt; Tuple[str, str]:
    &#34;&#34;&#34; Calculates ETL session loading period.
    
    This function is used when a new session is created. It recognizes a &#34;period&#34;
    dagrun option, which must be provided as two valid dates or datetimes considered
    as lower and upper bound of loading period. If a date-only upper bound is used,
    it will be increased to hold entire day (see examples).
    
    If this option was not specified, loading period will be set to interval of
    `[data_interval_start, data_interval_end]` Airflow variables 
    (see https://docs.astronomer.io/learn/scheduling-in-airflow for details).
    However, these dates will be converted to Airflow default timezone 
    (as they are defined in UTC).

    Args:
        context:    DAG execution context (optional)

    Returns:
        Tuple of two datetimes indicating lower- and upper-bound of loading period,
        converted to ISO-formatted strings (see `datetime.isoformat()`).

    Examples:
        Examples of DAG run configuration options and their conversion:

        ```
        {&#34;period&#34;: &#34;[2023-05-01, 2023-05-31]&#34;}
            -&gt; [&#34;2023-05-01T00:00:00&#34;, &#34;2023-06-01T00:00:00&#34;]
        {&#34;period&#34;: &#34;[2023-05-01, 2023-05-01]&#34;} 
            -&gt; [&#34;2023-05-01T00:00:00&#34;, &#34;2023-05-02T00:00:00&#34;]
        {&#34;period&#34;: &#34;[2023-05-01T12:00:00, 2023-05-01T14:00:00]&#34;} 
            -&gt; [&#34;2023-05-01T10:00:00&#34;, &#34;2023-05-01T14:00:00&#34;]
        ```

    &#34;&#34;&#34;
    context = context or get_current_context()

    if (period_str := context[&#39;dag_run&#39;].conf.get(&#39;period&#39;)):
        if not re.match(_FULL_REGX, period_str):
            raise AirflowFailException(&#39;Period must be specified as &#34;period&#34;: &#34;[&lt;date_from&gt;,&lt;date_to&gt;]&#34;&#39;)
        
        period = [isoparse(x.group(0)) for x in re.finditer(_TS_REGX, period_str)]
        if len(period) &lt; 2:
            raise AirflowFailException(&#39;Invalid period: two valid dates in YYYY-MM-DD format must be specified&#39;)

        # If no time part is provided in the upper period bound,
        # consider this to be date-only and add 1 day to align to days&#39;end
        # For example, specifying period = [&#34;2023-05-01&#34;, &#34;2023-05-01&#34;] will be converted
        # to [&#34;2023-05-01 00:00:00&#34;, &#34;2023-05-02 00:00:00&#34;]
        if period[1].hour == 0 and period[1].minute == 0 and period[1].second == 0:
            period[1] += timedelta(days=1)

        if period[1] &lt;= period[0]:
            raise AirflowFailException(&#39;Upper period bound must be greater than lower bound&#39;)
    else:
        period = [context[&#39;data_interval_start&#39;], context[&#39;data_interval_end&#39;]]
        period = [datetime_to_tz(x, TIMEZONE) for x in period]

    return tuple([x.isoformat() for x in period])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="astro_extras.operators.session.close_session"><code class="name flex">
<span>def <span class="ident">close_session</span></span>(<span>session: Union[<a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a>, airflow.models.xcom_arg.XComArg], upstream_task: Optional[Any] = None, dag: Optional[airflow.models.dag.DAG] = None, **kwargs) ‑> airflow.models.xcom_arg.XComArg</span>
</code></dt>
<dd>
<div class="desc"><p>Closes the ETL session.</p>
<p>Updates <code>public.sessions</code> table for currently running session
saving completion time and state. If all tasks in a DAG run were successfull,
session's state will be set to <code>success</code>, otherwise - to <code>error</code>. Note that
session closing task will also fail in later case in order to be
automatically included into further retrying attempts.</p>
<p>This function should be the last call in a DAG, and it will automatically try to link up
to the end of the task chain.</p>
<p>If a <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> class is used as a context manager, <code><a title="astro_extras.operators.session.close_session" href="#astro_extras.operators.session.close_session">close_session()</a></code> will be called
implicitly.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>session</code></strong></dt>
<dd>An object returned by <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code></dd>
<dt><strong><code>upstream_task</code></strong></dt>
<dd>A DAGs task which <code><a title="astro_extras.operators.session.close_session" href="#astro_extras.operators.session.close_session">close_session()</a></code> task
would be linked to. If not set, a last DAG's task will be used.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An <code>XComArg</code> object indicating the session was closed</p>
<h2 id="examples">Examples</h2>
<p>See <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> for examples</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close_session(
        session: Union[ETLSession, XComArg], 
        upstream_task: Optional[Any] = None,
        dag: Optional[DAG] = None,
        **kwargs) -&gt; XComArg:
    &#34;&#34;&#34; Closes the ETL session.

    Updates `public.sessions` table for currently running session
    saving completion time and state. If all tasks in a DAG run were successfull,
    session&#39;s state will be set to `success`, otherwise - to `error`. Note that 
    session closing task will also fail in later case in order to be
    automatically included into further retrying attempts.
    
    This function should be the last call in a DAG, and it will automatically try to link up 
    to the end of the task chain.
    
    If a `ETLSession` class is used as a context manager, `close_session` will be called
    implicitly.

    Args:
        session:    An object returned by `open_session`
        upstream_task:  A DAGs task which `close_session` task
            would be linked to. If not set, a last DAG&#39;s task will be used.

    Returns:
        An `XComArg` object indicating the session was closed

    Examples:
        See `open_session` for examples
    &#34;&#34;&#34;
    
    assert (dag := dag or DagContext.get_current_dag())
    if upstream_task is None:
        if not len(dag.tasks):
            raise ValueError(&#39;close_session must not be the first DAG operator&#39;)
        upstream_task = dag.tasks[-1]

    op = CloseSessionOperator(dag=dag, session=session, **kwargs)
    upstream_task.set_downstream(op)
    return XComArg(op)</code></pre>
</details>
</dd>
<dt id="astro_extras.operators.session.ensure_session"><code class="name flex">
<span>def <span class="ident">ensure_session</span></span>(<span>session: Union[<a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a>, airflow.models.xcom_arg.XComArg, ForwardRef(None)], context: Optional[airflow.utils.context.Context] = None) ‑> <a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></span>
</code></dt>
<dd>
<div class="desc"><p>Returns current session. If a placeholder object returned by <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> is passed in,
retrieves actual session from XCom. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>session</code></strong></dt>
<dd>Either the <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> instance or a placeholder returned by <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> call</dd>
<dt><strong><code>context</code></strong></dt>
<dd>DAG execution context (optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Current ETL session as <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> class instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ensure_session(session: Optional[Union[ETLSession, XComArg]], 
                   context: Optional[Context] = None) -&gt; ETLSession:
    &#34;&#34;&#34; Returns current session. If a placeholder object returned by `open_session` is passed in,
    retrieves actual session from XCom. 
    
    Args:
        session: Either the `ETLSession` instance or a placeholder returned by `open_session` call
        context:    DAG execution context (optional)

    Returns:
        Current ETL session as `ETLSession` class instance
    &#34;&#34;&#34;
    if session is None:
        return None
    if isinstance(session, ETLSession):
        return session
    if isinstance(session, XComArg):
        return get_current_session(context)
    raise TypeError(f&#39;Either ETLSession or XComArg expected, {session.__class__.__name__} found&#39;)</code></pre>
</details>
</dd>
<dt id="astro_extras.operators.session.get_current_session"><code class="name flex">
<span>def <span class="ident">get_current_session</span></span>(<span>context: Optional[airflow.utils.context.Context] = None) ‑> <a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves current session from XCom.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>context</code></strong></dt>
<dd>DAG execution context (optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Current ETL session as <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> class instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_current_session(context: Optional[Context] = None) -&gt; ETLSession:
    &#34;&#34;&#34; Retrieves current session from XCom.
    
    Args:
        context:    DAG execution context (optional)

    Returns:
        Current ETL session as `ETLSession` class instance
    &#34;&#34;&#34;
    context = context or get_current_context()
    return context[&#39;ti&#39;].xcom_pull(key=&#39;session&#39;)</code></pre>
</details>
</dd>
<dt id="astro_extras.operators.session.get_session_period"><code class="name flex">
<span>def <span class="ident">get_session_period</span></span>(<span>context: Optional[airflow.utils.context.Context] = None) ‑> Tuple[str, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates ETL session loading period.</p>
<p>This function is used when a new session is created. It recognizes a "period"
dagrun option, which must be provided as two valid dates or datetimes considered
as lower and upper bound of loading period. If a date-only upper bound is used,
it will be increased to hold entire day (see examples).</p>
<p>If this option was not specified, loading period will be set to interval of
<code>[data_interval_start, data_interval_end]</code> Airflow variables
(see <a href="https://docs.astronomer.io/learn/scheduling-in-airflow">https://docs.astronomer.io/learn/scheduling-in-airflow</a> for details).
However, these dates will be converted to Airflow default timezone
(as they are defined in UTC).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>context</code></strong></dt>
<dd>DAG execution context (optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Tuple of two datetimes indicating lower- and upper-bound of loading period,
converted to ISO-formatted strings (see <code>datetime.isoformat()</code>).</p>
<h2 id="examples">Examples</h2>
<p>Examples of DAG run configuration options and their conversion:</p>
<pre><code>{&quot;period&quot;: &quot;[2023-05-01, 2023-05-31]&quot;}
    -&gt; [&quot;2023-05-01T00:00:00&quot;, &quot;2023-06-01T00:00:00&quot;]
{&quot;period&quot;: &quot;[2023-05-01, 2023-05-01]&quot;} 
    -&gt; [&quot;2023-05-01T00:00:00&quot;, &quot;2023-05-02T00:00:00&quot;]
{&quot;period&quot;: &quot;[2023-05-01T12:00:00, 2023-05-01T14:00:00]&quot;} 
    -&gt; [&quot;2023-05-01T10:00:00&quot;, &quot;2023-05-01T14:00:00&quot;]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_session_period(context: Optional[Context] = None) -&gt; Tuple[str, str]:
    &#34;&#34;&#34; Calculates ETL session loading period.
    
    This function is used when a new session is created. It recognizes a &#34;period&#34;
    dagrun option, which must be provided as two valid dates or datetimes considered
    as lower and upper bound of loading period. If a date-only upper bound is used,
    it will be increased to hold entire day (see examples).
    
    If this option was not specified, loading period will be set to interval of
    `[data_interval_start, data_interval_end]` Airflow variables 
    (see https://docs.astronomer.io/learn/scheduling-in-airflow for details).
    However, these dates will be converted to Airflow default timezone 
    (as they are defined in UTC).

    Args:
        context:    DAG execution context (optional)

    Returns:
        Tuple of two datetimes indicating lower- and upper-bound of loading period,
        converted to ISO-formatted strings (see `datetime.isoformat()`).

    Examples:
        Examples of DAG run configuration options and their conversion:

        ```
        {&#34;period&#34;: &#34;[2023-05-01, 2023-05-31]&#34;}
            -&gt; [&#34;2023-05-01T00:00:00&#34;, &#34;2023-06-01T00:00:00&#34;]
        {&#34;period&#34;: &#34;[2023-05-01, 2023-05-01]&#34;} 
            -&gt; [&#34;2023-05-01T00:00:00&#34;, &#34;2023-05-02T00:00:00&#34;]
        {&#34;period&#34;: &#34;[2023-05-01T12:00:00, 2023-05-01T14:00:00]&#34;} 
            -&gt; [&#34;2023-05-01T10:00:00&#34;, &#34;2023-05-01T14:00:00&#34;]
        ```

    &#34;&#34;&#34;
    context = context or get_current_context()

    if (period_str := context[&#39;dag_run&#39;].conf.get(&#39;period&#39;)):
        if not re.match(_FULL_REGX, period_str):
            raise AirflowFailException(&#39;Period must be specified as &#34;period&#34;: &#34;[&lt;date_from&gt;,&lt;date_to&gt;]&#34;&#39;)
        
        period = [isoparse(x.group(0)) for x in re.finditer(_TS_REGX, period_str)]
        if len(period) &lt; 2:
            raise AirflowFailException(&#39;Invalid period: two valid dates in YYYY-MM-DD format must be specified&#39;)

        # If no time part is provided in the upper period bound,
        # consider this to be date-only and add 1 day to align to days&#39;end
        # For example, specifying period = [&#34;2023-05-01&#34;, &#34;2023-05-01&#34;] will be converted
        # to [&#34;2023-05-01 00:00:00&#34;, &#34;2023-05-02 00:00:00&#34;]
        if period[1].hour == 0 and period[1].minute == 0 and period[1].second == 0:
            period[1] += timedelta(days=1)

        if period[1] &lt;= period[0]:
            raise AirflowFailException(&#39;Upper period bound must be greater than lower bound&#39;)
    else:
        period = [context[&#39;data_interval_start&#39;], context[&#39;data_interval_end&#39;]]
        period = [datetime_to_tz(x, TIMEZONE) for x in period]

    return tuple([x.isoformat() for x in period])</code></pre>
</details>
</dd>
<dt id="astro_extras.operators.session.open_session"><code class="name flex">
<span>def <span class="ident">open_session</span></span>(<span>source_conn_id: str, destination_conn_id: str, session_conn_id: Optional[str] = None, dag: Optional[airflow.models.dag.DAG] = None, **kwargs) ‑> airflow.models.xcom_arg.XComArg</span>
</code></dt>
<dd>
<div class="desc"><p>Opens a new ETL session.</p>
<p>ETL session is a logical group of data transfers united by single identifier (<code>session_id</code>).
Sessions store information about data transfer source, target, data loading period
and completion state thus providing all necessary information about the data flow.</p>
<p>Call to the <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> should be the 1st call in a data transfer DAG. It will
create a new session by adding a record to <code>sessions</code> table and save a <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> instance
to XCom under "session" key. When using <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> class as a context manager,
the call is performed implicitly.</p>
<p>The session object could be retrieved from XCom and used within the queries.</p>
<p>Note that ETL session object has <code>period_start</code> and <code>period_end</code> fields, which
are calculated either automatically or could be specified manually by adding
<code>{"period": "[&lt;period_start&gt;, &lt;period_end&gt;]"}</code> parameter when DAG is started.
These fields can be used in data extraction queries to limit dataset like this:</p>
<pre><code>select * from data_table 
where some_date 
    between '{{ ti.xcom_pull(key="session").period_start }}'::timestamp
    and '{{ ti.xcom_pull(key="session").period_end }}'::timestamp
</code></pre>
<p>Technically, sessions are stored in a <code>public.sessions</code> table. Table DDL (for Postgres):</p>
<pre><code>create table public.sessions(
    session_id serial not null primary key,
    source text not null,
    target text not null,
    period timestamptz[2] not null,
    run_id text,
    started timestamptz not null,
    finished timestamptz,
    status varchar(10) not null 
        check (status in ('running', 'success', 'error'))
);
</code></pre>
<p>Every table where the data is saved should have an extra <code>session_id</code> field
referencing the <code>sessions</code> table. For example:</p>
<pre><code>create table public.test_table(
    session_id int not null references public.sessions(session_id),
    id int not null,
    name text not null
);
</code></pre>
<p>This allows to easily identify when particular record was loaded or
clean up after unsuccessfull attempts.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>source_conn_id</code></strong></dt>
<dd>Airflow connection where source data resides</dd>
<dt><strong><code>destination_conn_id</code></strong></dt>
<dd>Airflow connection to transfer data to</dd>
<dt><strong><code>session_conn_id</code></strong></dt>
<dd>ID of connection, where <code>sessions</code> table is located.
If not set, then <code>destination_conn_id</code> is used.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An <code>XComArg</code> placeholder object indicating the session was created
- due to Airflow's architecture actual session object could not be accessed
at this point, but it will automatically be converted to real one
upon passing in to the TaskFlow's task function (see examples).</p>
<h2 id="examples">Examples</h2>
<p>Create a DAG which opens a session, outputs info to log and closes it:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; with DAG(...) as dag, ETLSession('source', 'target') as session:
&gt;&gt;&gt;     @dag.task
&gt;&gt;&gt;     def print_session(session: Session):
&gt;&gt;&gt;         print(session)
&gt;&gt;&gt;     print_session(session)
</code></pre>
<p>Create a DAG with <code>open-session -&gt; transfer-test_table -&gt; close_session</code>
task sequence:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; with DAG(...) as dag:
&gt;&gt;&gt;     session = open_session('source', 'target')
&gt;&gt;&gt;     transfer_table('test_table', session=session)
&gt;&gt;&gt;     close_session(session)
</code></pre>
<p>Connections named <code>source</code> and <code>target</code> must be defined pointing to corresponding
databases. Table <code>public.sessions</code> must exists in the target database.</p>
<p>Table <code>test_table</code> must have the same structure in both databases, except
that <code>session_id</code> field must be added to the target table as 1st column.</p>
<p>See <code><a title="astro_extras.operators.table.transfer_table" href="table.html#astro_extras.operators.table.transfer_table">transfer_table()</a></code> function for details on transfer operation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_session(
        source_conn_id: str, 
        destination_conn_id: str, 
        session_conn_id: Optional[str] = None, 
        dag: Optional[DAG] = None,
        **kwargs) -&gt; XComArg:
    &#34;&#34;&#34; Opens a new ETL session.

    ETL session is a logical group of data transfers united by single identifier (`session_id`).
    Sessions store information about data transfer source, target, data loading period
    and completion state thus providing all necessary information about the data flow.

    Call to the `open_session` should be the 1st call in a data transfer DAG. It will
    create a new session by adding a record to `sessions` table and save a `ETLSession` instance 
    to XCom under &#34;session&#34; key. When using `ETLSession` class as a context manager,
    the call is performed implicitly.

    The session object could be retrieved from XCom and used within the queries.
        
    Note that ETL session object has `period_start` and `period_end` fields, which
    are calculated either automatically or could be specified manually by adding
    `{&#34;period&#34;: &#34;[&lt;period_start&gt;, &lt;period_end&gt;]&#34;}` parameter when DAG is started. 
    These fields can be used in data extraction queries to limit dataset like this:

        select * from data_table 
        where some_date 
            between &#39;{{ ti.xcom_pull(key=&#34;session&#34;).period_start }}&#39;::timestamp
            and &#39;{{ ti.xcom_pull(key=&#34;session&#34;).period_end }}&#39;::timestamp

    Technically, sessions are stored in a `public.sessions` table. Table DDL (for Postgres):

        create table public.sessions(
            session_id serial not null primary key,
            source text not null,
            target text not null,
            period timestamptz[2] not null,
            run_id text,
            started timestamptz not null,
            finished timestamptz,
            status varchar(10) not null 
                check (status in (&#39;running&#39;, &#39;success&#39;, &#39;error&#39;))
        );

    Every table where the data is saved should have an extra `session_id` field 
    referencing the `sessions` table. For example:

        create table public.test_table(
            session_id int not null references public.sessions(session_id),
            id int not null,
            name text not null
        );
    
    This allows to easily identify when particular record was loaded or 
    clean up after unsuccessfull attempts.

    Args:
        source_conn_id:   Airflow connection where source data resides
        destination_conn_id:   Airflow connection to transfer data to
        session_conn_id:   ID of connection, where `sessions` table is located.
            If not set, then `destination_conn_id` is used.

    Returns:
        An `XComArg` placeholder object indicating the session was created 
        - due to Airflow&#39;s architecture actual session object could not be accessed 
        at this point, but it will automatically be converted to real one
        upon passing in to the TaskFlow&#39;s task function (see examples).

    Examples:
        Create a DAG which opens a session, outputs info to log and closes it:

        &gt;&gt;&gt; with DAG(...) as dag, ETLSession(&#39;source&#39;, &#39;target&#39;) as session:
        &gt;&gt;&gt;     @dag.task
        &gt;&gt;&gt;     def print_session(session: Session):
        &gt;&gt;&gt;         print(session)
        &gt;&gt;&gt;     print_session(session)

        Create a DAG with `open-session -&gt; transfer-test_table -&gt; close_session`
        task sequence:

        &gt;&gt;&gt; with DAG(...) as dag:
        &gt;&gt;&gt;     session = open_session(&#39;source&#39;, &#39;target&#39;)
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)
        &gt;&gt;&gt;     close_session(session)

        Connections named `source` and `target` must be defined pointing to corresponding
        databases. Table `public.sessions` must exists in the target database.

        Table `test_table` must have the same structure in both databases, except
        that `session_id` field must be added to the target table as 1st column.

        See `astro_extras.operators.table.transfer_table` function for details on transfer operation.
    &#34;&#34;&#34;
    
    assert (dag := dag or DagContext.get_current_dag())
    return XComArg(OpenSessionOperator(
        dag=dag,
        source_conn_id=source_conn_id,
        destination_conn_id=destination_conn_id,
        session_conn_id=session_conn_id,
        **kwargs))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="astro_extras.operators.session.CloseSessionOperator"><code class="flex name class">
<span>class <span class="ident">CloseSessionOperator</span></span>
<span>(</span><span>*, session: Union[<a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a>, airflow.models.xcom_arg.XComArg, ForwardRef(None)] = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Session closing operator. Normally is used within <code><a title="astro_extras.operators.session.close_session" href="#astro_extras.operators.session.close_session">close_session()</a></code> function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CloseSessionOperator(BaseOperator):
    &#34;&#34;&#34; Session closing operator. Normally is used within `close_session` function &#34;&#34;&#34;

    def __init__(self,
                 *,
                 session: Union[ETLSession, XComArg, None] = None,
                 **kwargs):

        task_id = kwargs.pop(&#39;task_id&#39;, &#39;close-session&#39;)
        trigger_rule = kwargs.pop(&#39;trigger_rule&#39;, TriggerRule.ALL_DONE)
        super().__init__(task_id=task_id, trigger_rule=trigger_rule, **kwargs)
        self.session = session

    def execute(self, context: Context):
        self.session = ensure_session(self.session)

        dag_run = context[&#39;dag_run&#39;]
        failed_tasks = [ti for ti in dag_run.get_task_instances(state=TaskInstanceState.FAILED)]
        status = &#39;error&#39; if failed_tasks else &#39;success&#39;

        # TBD: use of database-neutral statement
        sql = f&#34;update public.sessions set finished=current_timestamp, status=&#39;{status}&#39; &#34; \
                   f&#34;where session_id={self.session.session_id}&#34;
        op = RawSQLOperator(
            task_id=self.task_id,
            python_callable=lambda : sql,
            conn_id=self.session.session_conn_id,
            response_size=1)
        op.execute(context)
        self.log.info(f&#39;Session {self.session.session_id} closed with status {status}&#39;)

        if status == &#39;error&#39;:
            raise AirflowException(&#39;Setting drives to idle&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>airflow.models.baseoperator.BaseOperator</li>
<li>airflow.models.abstractoperator.AbstractOperator</li>
<li>airflow.template.templater.Templater</li>
<li>airflow.utils.log.logging_mixin.LoggingMixin</li>
<li>airflow.models.taskmixin.DAGNode</li>
<li>airflow.models.taskmixin.DependencyMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="astro_extras.operators.session.CloseSessionOperator.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, context: airflow.utils.context.Context)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the main method to derive when creating an operator.
Context is the same dictionary used as when rendering jinja templates.</p>
<p>Refer to get_template_context for more context.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, context: Context):
    self.session = ensure_session(self.session)

    dag_run = context[&#39;dag_run&#39;]
    failed_tasks = [ti for ti in dag_run.get_task_instances(state=TaskInstanceState.FAILED)]
    status = &#39;error&#39; if failed_tasks else &#39;success&#39;

    # TBD: use of database-neutral statement
    sql = f&#34;update public.sessions set finished=current_timestamp, status=&#39;{status}&#39; &#34; \
               f&#34;where session_id={self.session.session_id}&#34;
    op = RawSQLOperator(
        task_id=self.task_id,
        python_callable=lambda : sql,
        conn_id=self.session.session_conn_id,
        response_size=1)
    op.execute(context)
    self.log.info(f&#39;Session {self.session.session_id} closed with status {status}&#39;)

    if status == &#39;error&#39;:
        raise AirflowException(&#39;Setting drives to idle&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="astro_extras.operators.session.ETLSession"><code class="flex name class">
<span>class <span class="ident">ETLSession</span></span>
<span>(</span><span>source_conn_id: str = None, destination_conn_id: str = None, session_conn_id: str = None, session_id: int = 0, period_start: str = None, period_end: str = None, dag: airflow.models.dag.DAG = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Session data object. Holds all ETL session attributes, can be pushed to XCom.
Implements context manager protocol (see examples).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>source_conn_id</code></strong></dt>
<dd>Source connection ID</dd>
<dt><strong><code>destination_conn_id</code></strong></dt>
<dd>Destination connection ID</dd>
<dt><strong><code>session_conn_id</code></strong></dt>
<dd>ID of connection, where <code>public.sessions</code> table is located.
If not set, then <code>destination_conn_id</code> is used</dd>
<dt><strong><code>session_id</code></strong></dt>
<dd>Actual session ID (automatically generated, do not set it)</dd>
<dt><strong><code>period_start</code></strong></dt>
<dd>Date and time of session period start as ISO-format string.
See <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> for details.</dd>
<dt><strong><code>period_end</code></strong></dt>
<dd>Date and time of session period end as ISO-format string.
See <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> for details.</dd>
<dt><strong><code>dag</code></strong></dt>
<dd>DAG, where the session was created. Used only to pass DAG's reference throught.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>Using <code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code> as context manager:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; with DAG(...) as dag, ETLSession('source', 'target') as session:
&gt;&gt;&gt;     transfer_table('test_table', session=session)
</code></pre>
<p>Explicit call to <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code>:
</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; with DAG(...) as dag:
&gt;&gt;&gt;     session = open_session('source', 'target')
&gt;&gt;&gt;     transfer_table('test_table', session=session)
&gt;&gt;&gt;     close_session(session)
</code></pre>
<p>Method generated by attrs for class ETLSession.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@define(slots=False)
class ETLSession:
    &#34;&#34;&#34; Session data object. Holds all ETL session attributes, can be pushed to XCom.
    Implements context manager protocol (see examples).

    Args:
        source_conn_id:   Source connection ID
        destination_conn_id:   Destination connection ID
        session_conn_id:   ID of connection, where `public.sessions` table is located.
            If not set, then `destination_conn_id` is used
        session_id:   Actual session ID (automatically generated, do not set it)
        period_start: Date and time of session period start as ISO-format string.
            See `open_session` for details.
        period_end: Date and time of session period end as ISO-format string.
            See `open_session` for details.
        dag: DAG, where the session was created. Used only to pass DAG&#39;s reference throught.

    Examples:
        Using `ETLSession` as context manager:
        &gt;&gt;&gt; with DAG(...) as dag, ETLSession(&#39;source&#39;, &#39;target&#39;) as session:
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)

        Explicit call to `open_session`:        
        &gt;&gt;&gt; with DAG(...) as dag:
        &gt;&gt;&gt;     session = open_session(&#39;source&#39;, &#39;target&#39;)
        &gt;&gt;&gt;     transfer_table(&#39;test_table&#39;, session=session)
        &gt;&gt;&gt;     close_session(session)
    &#34;&#34;&#34;
    source_conn_id: str = field(default=None)
    destination_conn_id: str = field(default=None)
    session_conn_id: str = field(default=None)
    session_id: int = field(default=0)
    period_start: str = field(default=None)
    period_end: str = field(default=None)
    dag: DAG = field(default=None)

    def __attrs_post_init__(self) -&gt; None:
        if not self.session_conn_id:
            self.session_conn_id = self.destination_conn_id

    def __getstate__(self):
        return self.__dict__

    def serialize(self):
        return {
            &#39;source_conn_id&#39;: self.source_conn_id,
            &#39;destination_conn_id&#39;: self.destination_conn_id,
            &#39;session_conn_id&#39;: self.session_conn_id,
            &#39;session_id&#39;: self.session_id,
            &#39;period_start&#39;: self.period_start,
            &#39;period_end&#39;: self.period_end,
        }

    @staticmethod
    def deserialize(data, version: int):
        return ETLSession(
            source_conn_id=data[&#39;source_conn_id&#39;],
            destination_conn_id=data[&#39;destination_conn_id&#39;],
            session_conn_id=data[&#39;session_conn_id&#39;],
            session_id=data[&#39;session_id&#39;],
            period_start=data[&#39;period_start&#39;],
            period_end=data[&#39;period_end&#39;],
        )

    def __enter__(self):
        self._actual_sesssion = open_session(
            source_conn_id=self.source_conn_id,
            destination_conn_id=self.destination_conn_id,
            session_conn_id=self.session_conn_id,
            dag=self.dag)
        return self._actual_sesssion

    def __exit__(self, type, value, traceback):
        dag = cast(DAG, DagContext.get_current_dag())
        if len(dag.tasks) &gt; 1:
            t1, t2 = dag.tasks[0], dag.tasks[1]
            if t1.task_id == &#39;open-session&#39; and &#39;open-session&#39; not in t2.upstream_task_ids:
                t2.set_upstream(t1)
        close_session(self._actual_sesssion).set_downstream(aql.cleanup())</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="astro_extras.operators.session.ETLSession.dag"><code class="name">var <span class="ident">dag</span> : airflow.models.dag.DAG</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.destination_conn_id"><code class="name">var <span class="ident">destination_conn_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.period_end"><code class="name">var <span class="ident">period_end</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.period_start"><code class="name">var <span class="ident">period_start</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.session_conn_id"><code class="name">var <span class="ident">session_conn_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.session_id"><code class="name">var <span class="ident">session_id</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="astro_extras.operators.session.ETLSession.source_conn_id"><code class="name">var <span class="ident">source_conn_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="astro_extras.operators.session.ETLSession.deserialize"><code class="name flex">
<span>def <span class="ident">deserialize</span></span>(<span>data, version: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def deserialize(data, version: int):
    return ETLSession(
        source_conn_id=data[&#39;source_conn_id&#39;],
        destination_conn_id=data[&#39;destination_conn_id&#39;],
        session_conn_id=data[&#39;session_conn_id&#39;],
        session_id=data[&#39;session_id&#39;],
        period_start=data[&#39;period_start&#39;],
        period_end=data[&#39;period_end&#39;],
    )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="astro_extras.operators.session.ETLSession.serialize"><code class="name flex">
<span>def <span class="ident">serialize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize(self):
    return {
        &#39;source_conn_id&#39;: self.source_conn_id,
        &#39;destination_conn_id&#39;: self.destination_conn_id,
        &#39;session_conn_id&#39;: self.session_conn_id,
        &#39;session_id&#39;: self.session_id,
        &#39;period_start&#39;: self.period_start,
        &#39;period_end&#39;: self.period_end,
    }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="astro_extras.operators.session.OpenSessionOperator"><code class="flex name class">
<span>class <span class="ident">OpenSessionOperator</span></span>
<span>(</span><span>*, source_conn_id: Optional[str] = 'default', destination_conn_id: Optional[str] = 'default', session_conn_id: Optional[str] = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Session opening operator. Normally is used within <code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session()</a></code> function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OpenSessionOperator(BaseOperator):
    &#34;&#34;&#34; Session opening operator. Normally is used within `open_session` function &#34;&#34;&#34;

    def __init__(self,
                 *,
                 source_conn_id: Optional[str] = &#39;default&#39;,
                 destination_conn_id: Optional[str] = &#39;default&#39;,
                 session_conn_id: Optional[str] = None,
                 **kwargs):

        task_id = kwargs.pop(&#39;task_id&#39;, &#39;open-session&#39;)
        super().__init__(task_id=task_id, **kwargs)

        self.source_conn_id = source_conn_id
        self.destination_conn_id = destination_conn_id
        self.session_conn_id = session_conn_id if session_conn_id else destination_conn_id
        self.session: ETLSession = None

    def _new_session(self, period_start: str, period_end: str, context: Context) -&gt; int:
        # TBD: use of database-neutral statement
        sql = f&#34;&#34;&#34;insert into public.sessions(source, target, period, started, status, run_id) 
            values(&#39;{self.source_conn_id}&#39;,&#39;{self.destination_conn_id}&#39;,&#39;{{ {period_start}, {period_end} }}&#39;, 
            &#39;{datetime.now()}&#39;,&#39;running&#39;,&#39;{context[&#39;run_id&#39;]}&#39;) returning session_id&#34;&#34;&#34;

        op = RawSQLOperator(
            task_id=self.task_id,
            python_callable=lambda : sql,
            conn_id=self.session_conn_id,
            handler=lambda result: result.fetchone(),
            response_size=1)
        
        return op.execute(context)[0]

    def execute(self, context: Context):
        period_start, period_end = get_session_period(context)
        session_id = self._new_session(period_start, period_end, context)
        self.log.info(f&#39;New session {session_id} for period [{period_start},{period_end}] started&#39;)

        session = ETLSession(
            source_conn_id=self.source_conn_id,
            destination_conn_id=self.destination_conn_id, 
            session_id=session_id, 
            session_conn_id=self.session_conn_id,
            period_start=period_start,
            period_end=period_end)
        
        context[&#39;ti&#39;].xcom_push(key=&#39;session&#39;, value=session)
        return session</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>airflow.models.baseoperator.BaseOperator</li>
<li>airflow.models.abstractoperator.AbstractOperator</li>
<li>airflow.template.templater.Templater</li>
<li>airflow.utils.log.logging_mixin.LoggingMixin</li>
<li>airflow.models.taskmixin.DAGNode</li>
<li>airflow.models.taskmixin.DependencyMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="astro_extras.operators.session.OpenSessionOperator.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, context: airflow.utils.context.Context)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the main method to derive when creating an operator.
Context is the same dictionary used as when rendering jinja templates.</p>
<p>Refer to get_template_context for more context.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, context: Context):
    period_start, period_end = get_session_period(context)
    session_id = self._new_session(period_start, period_end, context)
    self.log.info(f&#39;New session {session_id} for period [{period_start},{period_end}] started&#39;)

    session = ETLSession(
        source_conn_id=self.source_conn_id,
        destination_conn_id=self.destination_conn_id, 
        session_id=session_id, 
        session_conn_id=self.session_conn_id,
        period_start=period_start,
        period_end=period_end)
    
    context[&#39;ti&#39;].xcom_push(key=&#39;session&#39;, value=session)
    return session</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="astro_extras.operators" href="index.html">astro_extras.operators</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="astro_extras.operators.session.close_session" href="#astro_extras.operators.session.close_session">close_session</a></code></li>
<li><code><a title="astro_extras.operators.session.ensure_session" href="#astro_extras.operators.session.ensure_session">ensure_session</a></code></li>
<li><code><a title="astro_extras.operators.session.get_current_session" href="#astro_extras.operators.session.get_current_session">get_current_session</a></code></li>
<li><code><a title="astro_extras.operators.session.get_session_period" href="#astro_extras.operators.session.get_session_period">get_session_period</a></code></li>
<li><code><a title="astro_extras.operators.session.open_session" href="#astro_extras.operators.session.open_session">open_session</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="astro_extras.operators.session.CloseSessionOperator" href="#astro_extras.operators.session.CloseSessionOperator">CloseSessionOperator</a></code></h4>
<ul class="">
<li><code><a title="astro_extras.operators.session.CloseSessionOperator.execute" href="#astro_extras.operators.session.CloseSessionOperator.execute">execute</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="astro_extras.operators.session.ETLSession" href="#astro_extras.operators.session.ETLSession">ETLSession</a></code></h4>
<ul class="two-column">
<li><code><a title="astro_extras.operators.session.ETLSession.dag" href="#astro_extras.operators.session.ETLSession.dag">dag</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.deserialize" href="#astro_extras.operators.session.ETLSession.deserialize">deserialize</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.destination_conn_id" href="#astro_extras.operators.session.ETLSession.destination_conn_id">destination_conn_id</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.period_end" href="#astro_extras.operators.session.ETLSession.period_end">period_end</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.period_start" href="#astro_extras.operators.session.ETLSession.period_start">period_start</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.serialize" href="#astro_extras.operators.session.ETLSession.serialize">serialize</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.session_conn_id" href="#astro_extras.operators.session.ETLSession.session_conn_id">session_conn_id</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.session_id" href="#astro_extras.operators.session.ETLSession.session_id">session_id</a></code></li>
<li><code><a title="astro_extras.operators.session.ETLSession.source_conn_id" href="#astro_extras.operators.session.ETLSession.source_conn_id">source_conn_id</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="astro_extras.operators.session.OpenSessionOperator" href="#astro_extras.operators.session.OpenSessionOperator">OpenSessionOperator</a></code></h4>
<ul class="">
<li><code><a title="astro_extras.operators.session.OpenSessionOperator.execute" href="#astro_extras.operators.session.OpenSessionOperator.execute">execute</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>